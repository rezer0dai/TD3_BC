ENV = "panda-reach"
SEED = 0
EVAL_FREQ = 5e3
MAX_TIMESTEPS = 1e6
# TD3
EXPL_NOISE = 0.1
BATCH_SIZE = 256
DISCOUNT = 0.99
TAU = 0.005
POLICY_NOISE = 0.2
NOISE_CLIP = 0.5
POLICY_FREQ = 2
# TD3 + BC
ALPHA = 2.5
NORMALIZE = True
# OPEN AI TD3 BASELINE TRAINING
STEPS_PER_EPOCH = 4000
EPOCHS =100
REPLAY_SIZE = 1e6
START_STEPS = 10000
UPDATE_AFTER = 1000
UPDATE_EVERY = 50
# HER
HER_PER_EP = 20
HER_RATIO = 1.

